# =============================================================================
# QBM CI Workflow - Phase 11
# =============================================================================
# Tier A tests run on every push/PR (CPU-only, no GPU, no PyG)
# Tier B tests require self-hosted runner with GPU + QBM_FULLPOWER_READY=1
# =============================================================================
name: QBM CI

on:
  push:
    branches: [main, develop]
    tags:
      - 'v*'
  pull_request:
    branches: [main]

env:
  # Phase 10.1d: PyG is opt-in only - disabled in CI by default
  # This prevents Windows DLL crashes and ensures clean builds
  QBM_ENABLE_PYG: "0"
  # Disable GPU for CI (Tier A tests are CPU-only)
  CUDA_VISIBLE_DEVICES: ""
  # Use fixture mode for CI (deterministic, no large corpora needed)
  QBM_USE_FIXTURE: "1"

jobs:
  # ===========================================================================
  # Tier A: CPU/Fixture Tests (runs everywhere)
  # ===========================================================================
  tier-a-tests:
    name: Tier A Tests (CPU-only)
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        python-version: ["3.11"]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Verify PyG is disabled
        run: |
          echo "QBM_ENABLE_PYG=$QBM_ENABLE_PYG (should be 0)"
          python -c "import os; assert os.getenv('QBM_ENABLE_PYG', '0') != '1', 'PyG should be disabled in CI'"
      
      - name: Bootstrap CI fixture (build indexes from committed fixture data)
        run: |
          python scripts/ci_bootstrap_fixture.py --fixture data/test_fixtures/fixture_v1 --out data/indexes/tafsir
      
      - name: Validate concept_index_v3 schema (check-only, no rewrites)
        run: |
          python scripts/normalize_concept_index_v3.py --check
      
      - name: Build chunked evidence index (from fixture in CI)
        run: |
          python scripts/build_chunked_evidence_index.py
      
      - name: Preflight gate - verify fixture bootstrap worked
        run: |
          python -c "
          import os
          os.environ['QBM_USE_FIXTURE']='1'
          from pathlib import Path
          
          # Check tafsir indexes exist
          tafsir_dir = Path('data/indexes/tafsir')
          sources = ['ibn_kathir', 'tabari', 'qurtubi', 'saadi', 'jalalayn', 'baghawi', 'muyassar']
          for s in sources:
              f = tafsir_dir / f'{s}.json'
              assert f.exists(), f'Missing tafsir index: {f}'
          print('✓ All 7 tafsir indexes present')
          
          # Check chunked evidence index exists
          chunked = Path('data/evidence/evidence_index_v2_chunked.jsonl')
          assert chunked.exists(), f'Missing chunked evidence index: {chunked}'
          print(f'✓ Chunked evidence index present ({chunked.stat().st_size} bytes)')
          
          # Check verse index exists
          verse_idx = tafsir_dir / 'verse_index.json'
          assert verse_idx.exists(), f'Missing verse index: {verse_idx}'
          print('✓ Verse index present')
          
          print('\\n✓ All preflight gates passed')
          "
      
      - name: Run Tier A tests (CPU-only, no GPU, no PyG)
        run: |
          python -m pytest tests/ -v --tb=short \
            -m "not gpu and not slow and not tier_b" \
            --ignore=tests/test_end_to_end.py \
            --ignore=tests/test_scholarly_spotcheck.py \
            --ignore=tests/test_hybrid_retrieval.py \
            --ignore=tests/test_surah_ref_evidence.py \
            --ignore=tests/test_chunked_evidence_index.py \
            --ignore=tests/test_stratified_retriever.py \
            --ignore=tests/test_proof_endpoint_integration.py \
            --ignore=tests/test_mandatory_proof.py \
            --ignore=tests/test_gold_data_semantics.py \
            --ignore=tests/test_canonical_path.py \
            --ignore=tests/test_no_fallback_invariant.py \
            --ignore=tests/test_no_generic_default_verses.py \
            --ignore=tests/test_query_router.py \
            --ignore=tests/test_legendary_questions_api_runtime.py \
            --ignore=tests/test_proof_pagination.py \
            --ignore=tests/phase1/test_normalization.py \
            --ignore=tests/phase8/test_behavior_patience_retrieval.py
      
      - name: Check test collection
        run: |
          python -m pytest --collect-only tests/ -q

      - name: Benchmark smoke (proof-only)
        run: |
          python scripts/run_qbm_benchmark.py \
            --dataset data/benchmarks/qbm_legendary_200.v1.jsonl \
            --smoke \
            --proof-only \
            --ci

  lint:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      
      - name: Install linting tools
        run: |
          python -m pip install --upgrade pip
          pip install ruff
      
      - name: Run ruff check
        run: |
          ruff check src/ tests/ --ignore=E501,F401,F841 --exit-zero

  # ===========================================================================
  # Repo Hygiene: Check for Windows reserved filenames
  # ===========================================================================
  repo-hygiene:
    name: Repo Hygiene Checks
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Check for Windows reserved filenames
        run: |
          # Windows reserved names that poison repos
          RESERVED="nul con prn aux com1 com2 com3 com4 com5 com6 com7 com8 com9 lpt1 lpt2 lpt3 lpt4 lpt5 lpt6 lpt7 lpt8 lpt9"
          
          echo "Checking for Windows reserved filenames..."
          FOUND=""
          for name in $RESERVED; do
            # Check for exact matches (case-insensitive)
            MATCHES=$(find . -iname "$name" -o -iname "$name.*" 2>/dev/null | grep -v ".git/" || true)
            if [ -n "$MATCHES" ]; then
              echo "ERROR: Found reserved filename '$name': $MATCHES"
              FOUND="$FOUND $MATCHES"
            fi
          done
          
          if [ -n "$FOUND" ]; then
            echo "::error::Windows reserved filenames found:$FOUND"
            exit 1
          fi
          
          echo "✅ No Windows reserved filenames found"

  # ===========================================================================
  # Audit Pack Generation and Validation (Enterprise Mode)
  # ===========================================================================
  audit-pack:
    name: Audit Pack Generation
    runs-on: ubuntu-latest
    needs: [tier-a-tests, lint]  # Only run after tests pass
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Verify clean tree
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            echo "ERROR: Working tree is not clean"
            git status --porcelain
            exit 1
          fi
          echo "✅ Working tree is clean"
      
      - name: Generate audit pack (strict mode)
        run: |
          python scripts/generate_audit_pack.py --strict
      
      - name: Validate audit pack (CI mode)
        env:
          QBM_REQUIRE_AUDIT_PACK: "1"
        run: |
          python -m pytest tests/test_audit_pack_phase7.py -v --tb=short -k "audit_pack"
      
      - name: Package audit pack
        run: |
          cd artifacts
          zip -r audit_pack.zip audit_pack/
      
      - name: Upload audit pack artifact
        uses: actions/upload-artifact@v4
        with:
          name: audit-pack-${{ github.sha }}
          path: artifacts/audit_pack.zip
          retention-days: 90

  # ===========================================================================
  # Release Build: Full KB + GPU Proof (manual trigger only)
  # ===========================================================================
  release-build:
    name: Release Build (KB + GPU Proof)
    runs-on: ubuntu-latest
    # Only run on manual trigger or release
    if: github.event_name == 'workflow_dispatch' || startsWith(github.ref, 'refs/tags/')
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Verify clean tree
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            echo "ERROR: Working tree is not clean"
            git status --porcelain
            exit 1
          fi
          echo "✅ Working tree is clean"
      
      - name: Build KB (CPU mode - no GPU proof)
        run: |
          python scripts/build_kb.py --full --device cpu
        # Note: Using CPU in CI since no GPU available
        # GPU proof requires self-hosted runner with GPU (see gpu-release-build job)
      
      - name: Generate audit pack (strict mode)
        run: |
          python scripts/generate_audit_pack.py --strict
      
      - name: Validate audit pack (CI mode)
        env:
          QBM_REQUIRE_AUDIT_PACK: "1"
        run: |
          python -m pytest tests/test_audit_pack_phase7.py -v --tb=short -k "audit_pack"
      
      - name: Package release artifacts
        run: |
          mkdir -p release
          cd artifacts && zip -r ../release/audit_pack.zip audit_pack/
          cd ../data/kb && zip -r ../../release/kb.zip .
      
      - name: Upload release artifacts
        uses: actions/upload-artifact@v4
        with:
          name: release-${{ github.sha }}
          path: release/
          retention-days: 90

  # ===========================================================================
  # GPU Release Build: Full KB + GPU Proof (self-hosted GPU runner)
  # ===========================================================================
  gpu-release-build:
    name: GPU Release Build (Self-Hosted)
    runs-on: [self-hosted, gpu]
    # Only run on manual trigger with GPU requested
    if: github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Verify clean tree
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            echo "ERROR: Working tree is not clean"
            git status --porcelain
            exit 1
          fi
          echo "✅ Working tree is clean"
      
      - name: Verify GPU availability
        run: |
          python -c "import torch; assert torch.cuda.is_available(), 'CUDA not available'; print(f'GPU: {torch.cuda.get_device_name(0)}')"
          nvidia-smi
      
      - name: Build KB with GPU proof
        run: |
          python scripts/build_kb.py --full --gpu-proof --device cuda
      
      - name: Validate GPU proof
        run: |
          python scripts/gpu_proof_instrumentation.py --validate artifacts/audit_pack/gpu_proof/gpu_computation_proof.json
      
      - name: Generate audit pack (strict mode)
        run: |
          python scripts/generate_audit_pack.py --strict
      
      - name: Validate audit pack (CI mode)
        env:
          QBM_REQUIRE_AUDIT_PACK: "1"
        run: |
          python -m pytest tests/test_audit_pack_phase7.py -v --tb=short -k "audit_pack"
      
      - name: Package release artifacts with GPU proof
        run: |
          mkdir -p release
          cd artifacts && zip -r ../release/audit_pack_gpu.zip audit_pack/
          cd ../data/kb && zip -r ../../release/kb.zip .
      
      - name: Upload GPU release artifacts
        uses: actions/upload-artifact@v4
        with:
          name: gpu-release-${{ github.sha }}
          path: release/
          retention-days: 90

  # ===========================================================================
  # Frontend E2E Tests (Playwright)
  # ===========================================================================
  frontend-e2e:
    name: Frontend E2E Tests
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: qbm-frontendv3
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: qbm-frontendv3/package-lock.json
      
      - name: Install dependencies
        run: npm ci
      
      - name: Install Playwright browsers
        run: npx playwright install --with-deps chromium
      
      - name: Build frontend
        run: npm run build
        env:
          NEXT_PUBLIC_API_URL: http://localhost:8000
      
      - name: Run Playwright tests
        run: npx playwright test --reporter=html,list
        continue-on-error: true  # Don't fail CI on E2E failures (smoke test only)
      
      - name: Upload Playwright report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright-report
          path: qbm-frontendv3/playwright-report/
          retention-days: 7
          if-no-files-found: ignore
