# =============================================================================
# QBM CI Workflow - Phase 11
# =============================================================================
# Tier A tests run on every push/PR (CPU-only, no GPU, no PyG)
# Tier B tests require self-hosted runner with GPU + QBM_FULLPOWER_READY=1
# =============================================================================
name: QBM CI

on:
  push:
    branches: [main, develop]
    tags:
      - 'v*'
  pull_request:
    branches: [main]

env:
  # Phase 10.1d: PyG is opt-in only - disabled in CI by default
  # This prevents Windows DLL crashes and ensures clean builds
  QBM_ENABLE_PYG: "0"
  # Disable GPU for CI (Tier A tests are CPU-only)
  CUDA_VISIBLE_DEVICES: ""
  # Dataset mode: fixture (CI on main) vs full (tags/releases)
  # Primary switch - all code should use get_dataset_mode() from src.core.data_profile
  QBM_DATASET_MODE: "fixture"
  # Legacy flags for backwards compatibility
  QBM_USE_FIXTURE: "1"
  QBM_DATA_MODE: "fixture"

jobs:
  # ===========================================================================
  # Tier A: CPU/Fixture Tests (runs everywhere)
  # ===========================================================================
  tier-a-tests:
    name: Tier A Tests (CPU-only)
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        python-version: ["3.11"]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Verify PyG is disabled
        run: |
          echo "QBM_ENABLE_PYG=$QBM_ENABLE_PYG (should be 0)"
          python -c "import os; assert os.getenv('QBM_ENABLE_PYG', '0') != '1', 'PyG should be disabled in CI'"
      
      - name: CI Bootstrap All (single entrypoint for all artifact generation)
        run: |
          python scripts/ci_bootstrap_all.py
      
      - name: Validate concept_index_v3 schema (check-only, no rewrites)
        run: |
          python scripts/normalize_concept_index_v3.py --check
      
      - name: Run Tier A tests (CPU-only, fixture mode, no release-only tests)
        run: |
          python -m pytest tests/ -v --tb=short \
            -m "not gpu and not slow and not tier_b and not deprecated_ssot_v2 and not release_only and not full_graph" \
            --ignore=tests/test_end_to_end.py \
            --ignore=tests/test_scholarly_spotcheck.py \
            --ignore=tests/test_hybrid_retrieval.py \
            --ignore=tests/test_surah_ref_evidence.py \
            --ignore=tests/test_chunked_evidence_index.py \
            --ignore=tests/test_stratified_retriever.py \
            --ignore=tests/test_proof_endpoint_integration.py \
            --ignore=tests/test_mandatory_proof.py \
            --ignore=tests/test_gold_data_semantics.py \
            --ignore=tests/test_canonical_path.py \
            --ignore=tests/test_no_fallback_invariant.py \
            --ignore=tests/test_no_generic_default_verses.py \
            --ignore=tests/test_query_router.py \
            --ignore=tests/test_legendary_questions_api_runtime.py \
            --ignore=tests/test_proof_pagination.py \
            --ignore=tests/phase1/test_normalization.py \
            --ignore=tests/phase8/test_behavior_patience_retrieval.py \
            --ignore=tests/test_concept_index_v2.py \
            --ignore=tests/test_concept_map_completeness.py \
            --ignore=tests/test_semantic_graph_v2.py \
            --ignore=tests/test_audit_pack_phase7.py \
            --ignore=tests/test_benchmark_ci.py \
            --ignore=tests/ai/test_unified.py \
            --ignore=tests/ai/test_knowledge_graph.py \
            --ignore=tests/test_validation_gates_v3.py \
            --ignore=tests/test_graph_causal_engine.py \
            --ignore=tests/test_evidence_backed_graphs.py \
            --ignore=tests/test_legendary_questions.py \
            --ignore=tests/test_legendary_questions_full.py \
            --ignore=tests/test_legendary_planner.py \
            --ignore=tests/test_kb_phase3.py \
            --ignore=tests/test_answer_generation_deterministic.py \
            --ignore=tests/test_benchmark_intent_classifier.py \
            --ignore=tests/test_optional_torch_geometric.py \
            --ignore=tests/test_concept_evidence_index.py \
            --ignore=tests/phase5/test_validation_gates.py \
            --ignore=tests/phase7/test_graph_projection.py \
            --ignore=tests/phase8/test_all_behaviors_contract.py
      
      - name: Check test collection
        run: |
          python -m pytest --collect-only tests/ -q

      - name: Benchmark smoke (proof-only)
        run: |
          python scripts/run_qbm_benchmark.py \
            --dataset data/benchmarks/qbm_legendary_200.v1.jsonl \
            --smoke \
            --proof-only \
            --ci

  lint:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      
      - name: Install linting tools
        run: |
          python -m pip install --upgrade pip
          pip install ruff
      
      - name: Run ruff check
        run: |
          ruff check src/ tests/ --ignore=E501,F401,F841 --exit-zero

  # ===========================================================================
  # Repo Hygiene: Check for Windows reserved filenames
  # ===========================================================================
  repo-hygiene:
    name: Repo Hygiene Checks
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Check for Windows reserved filenames
        run: |
          # Windows reserved names that poison repos
          RESERVED="nul con prn aux com1 com2 com3 com4 com5 com6 com7 com8 com9 lpt1 lpt2 lpt3 lpt4 lpt5 lpt6 lpt7 lpt8 lpt9"
          
          echo "Checking for Windows reserved filenames..."
          FOUND=""
          for name in $RESERVED; do
            # Check for exact matches (case-insensitive)
            MATCHES=$(find . -iname "$name" -o -iname "$name.*" 2>/dev/null | grep -v ".git/" || true)
            if [ -n "$MATCHES" ]; then
              echo "ERROR: Found reserved filename '$name': $MATCHES"
              FOUND="$FOUND $MATCHES"
            fi
          done
          
          if [ -n "$FOUND" ]; then
            echo "::error::Windows reserved filenames found:$FOUND"
            exit 1
          fi
          
          echo "✅ No Windows reserved filenames found"

  # ===========================================================================
  # Audit Pack Generation and Validation (Enterprise Mode)
  # Only runs on tags (releases) or manual workflow_dispatch - requires full SSOT
  # ===========================================================================
  audit-pack:
    name: Audit Pack Generation
    runs-on: ubuntu-latest
    needs: [tier-a-tests, lint]  # Only run after tests pass
    if: startsWith(github.ref, 'refs/tags/v') || github.event_name == 'workflow_dispatch'
    env:
      QBM_DATASET_MODE: "full"
      QBM_DATA_MODE: "full"
      QBM_USE_FIXTURE: "0"
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Verify clean tree
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            echo "ERROR: Working tree is not clean"
            git status --porcelain
            exit 1
          fi
          echo "✅ Working tree is clean"
      
      - name: Generate audit pack (strict mode)
        run: |
          python scripts/generate_audit_pack.py --strict
      
      - name: Validate audit pack (CI mode)
        env:
          QBM_REQUIRE_AUDIT_PACK: "1"
        run: |
          python -m pytest tests/test_audit_pack_phase7.py -v --tb=short -k "audit_pack"
      
      - name: Package audit pack
        run: |
          cd artifacts
          zip -r audit_pack.zip audit_pack/
      
      - name: Upload audit pack artifact
        uses: actions/upload-artifact@v4
        with:
          name: audit-pack-${{ github.sha }}
          path: artifacts/audit_pack.zip
          retention-days: 90

  # ===========================================================================
  # Release Build: Full KB + GPU Proof (manual trigger only)
  # ===========================================================================
  release-build:
    name: Release Build (KB + GPU Proof)
    runs-on: ubuntu-latest
    # Only run on manual trigger or release
    if: github.event_name == 'workflow_dispatch' || startsWith(github.ref, 'refs/tags/')
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Verify clean tree
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            echo "ERROR: Working tree is not clean"
            git status --porcelain
            exit 1
          fi
          echo "✅ Working tree is clean"
      
      - name: Build KB (CPU mode - no GPU proof)
        run: |
          python scripts/build_kb.py --full --device cpu
        # Note: Using CPU in CI since no GPU available
        # GPU proof requires self-hosted runner with GPU (see gpu-release-build job)
      
      - name: Generate audit pack (strict mode)
        run: |
          python scripts/generate_audit_pack.py --strict
      
      - name: Validate audit pack (CI mode)
        env:
          QBM_REQUIRE_AUDIT_PACK: "1"
        run: |
          python -m pytest tests/test_audit_pack_phase7.py -v --tb=short -k "audit_pack"
      
      - name: Package release artifacts
        run: |
          mkdir -p release
          cd artifacts && zip -r ../release/audit_pack.zip audit_pack/
          cd ../data/kb && zip -r ../../release/kb.zip .
      
      - name: Upload release artifacts
        uses: actions/upload-artifact@v4
        with:
          name: release-${{ github.sha }}
          path: release/
          retention-days: 90

  # ===========================================================================
  # GPU Release Build: Full KB + GPU Proof (self-hosted GPU runner)
  # ===========================================================================
  gpu-release-build:
    name: GPU Release Build (Self-Hosted)
    runs-on: [self-hosted, gpu]
    # Only run on manual trigger with GPU requested
    if: github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Verify clean tree
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            echo "ERROR: Working tree is not clean"
            git status --porcelain
            exit 1
          fi
          echo "✅ Working tree is clean"
      
      - name: Verify GPU availability
        run: |
          python -c "import torch; assert torch.cuda.is_available(), 'CUDA not available'; print(f'GPU: {torch.cuda.get_device_name(0)}')"
          nvidia-smi
      
      - name: Build KB with GPU proof
        run: |
          python scripts/build_kb.py --full --gpu-proof --device cuda
      
      - name: Validate GPU proof
        run: |
          python scripts/gpu_proof_instrumentation.py --validate artifacts/audit_pack/gpu_proof/gpu_computation_proof.json
      
      - name: Generate audit pack (strict mode)
        run: |
          python scripts/generate_audit_pack.py --strict
      
      - name: Validate audit pack (CI mode)
        env:
          QBM_REQUIRE_AUDIT_PACK: "1"
        run: |
          python -m pytest tests/test_audit_pack_phase7.py -v --tb=short -k "audit_pack"
      
      - name: Package release artifacts with GPU proof
        run: |
          mkdir -p release
          cd artifacts && zip -r ../release/audit_pack_gpu.zip audit_pack/
          cd ../data/kb && zip -r ../../release/kb.zip .
      
      - name: Upload GPU release artifacts
        uses: actions/upload-artifact@v4
        with:
          name: gpu-release-${{ github.sha }}
          path: release/
          retention-days: 90

  # ===========================================================================
  # Frontend E2E Tests (Playwright)
  # ===========================================================================
  frontend-e2e:
    name: Frontend E2E Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python (for backend)
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Bootstrap CI fixture data
        run: python scripts/ci_bootstrap_all.py
        env:
          QBM_USE_FIXTURE: "1"
      
      - name: Start backend API
        run: |
          uvicorn src.api.main:app --host 127.0.0.1 --port 8000 &
          echo "Backend started in background"
        env:
          QBM_USE_FIXTURE: "1"
      
      - name: Wait for backend to be ready
        run: |
          echo "Waiting for backend API..."
          for i in {1..30}; do
            if curl -s http://127.0.0.1:8000/health > /dev/null 2>&1; then
              echo "✅ Backend is ready"
              exit 0
            fi
            echo "Attempt $i/30 - waiting..."
            sleep 2
          done
          echo "❌ Backend failed to start"
          exit 1
      
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: qbm-frontendv3/package-lock.json
      
      - name: Install frontend dependencies
        working-directory: qbm-frontendv3
        run: npm ci
      
      - name: Install Playwright browsers
        working-directory: qbm-frontendv3
        run: npx playwright install --with-deps chromium
      
      - name: Build frontend
        working-directory: qbm-frontendv3
        run: npm run build
        env:
          NEXT_PUBLIC_API_URL: http://127.0.0.1:8000
          NEXT_PUBLIC_QBM_BACKEND_URL: http://127.0.0.1:8000
      
      - name: Run Playwright tests
        working-directory: qbm-frontendv3
        run: npx playwright test --reporter=html,list
        env:
          NEXT_PUBLIC_API_URL: http://127.0.0.1:8000
          NEXT_PUBLIC_QBM_BACKEND_URL: http://127.0.0.1:8000
        continue-on-error: true  # Don't fail CI on E2E failures (smoke test only)
      
      - name: Upload Playwright report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright-report
          path: qbm-frontendv3/playwright-report/
          retention-days: 7
          if-no-files-found: ignore
